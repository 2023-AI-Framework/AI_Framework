{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "results = {\n",
    "}\n",
    "\n",
    "for model in ['resnet18', 'resnet34', 'resnet50', 'resnet101']:\n",
    "    results[model] = dict()\n",
    "    for mixed in ['no', 'fp16']:\n",
    "        results[model][mixed] = dict()\n",
    "        path = f'csv/{model}_{mixed}.csv'\n",
    "        data = pandas.read_csv(path)\n",
    "        \n",
    "        for index, inmodel in enumerate(data['model']):\n",
    "            splited_data = inmodel.split('_')\n",
    "            batch_size = splited_data[1]\n",
    "            num_workers = splited_data[2]\n",
    "            ga = splited_data[3]\n",
    "\n",
    "            if batch_size not in list(results[model][mixed].keys()):\n",
    "                results[model][mixed][batch_size] = dict()\n",
    "            if num_workers not in list(results[model][mixed][batch_size].keys()):\n",
    "                results[model][mixed][batch_size][num_workers] = dict()\n",
    "            if ga not in list(results[model][mixed][batch_size][num_workers].keys()):\n",
    "                results[model][mixed][batch_size][num_workers][ga] = dict() \n",
    "\n",
    "            results[model][mixed][batch_size][num_workers][ga]['cuda_forward_time'] = []\n",
    "            results[model][mixed][batch_size][num_workers][ga]['cuda_calc_loss_time'] = []\n",
    "            results[model][mixed][batch_size][num_workers][ga]['cuda_backward_time'] = []\n",
    "            results[model][mixed][batch_size][num_workers][ga]['cuda_update_time'] = []\n",
    "            \n",
    "            if '_32_' in inmodel:\n",
    "                iters_epoch = 7715\n",
    "            elif '_64_' in inmodel:\n",
    "                iters_epoch = 3810\n",
    "            elif '_128_' in inmodel:\n",
    "                iters_epoch = 1855\n",
    "            elif '_256_' in inmodel:\n",
    "                iters_epoch = 880\n",
    "            scale = iters_epoch / 1_000\n",
    "            results[model][mixed][batch_size][num_workers][ga]['cuda_forward_time'].append(list(data['cuda_forward_time'])[index] * scale)\n",
    "            results[model][mixed][batch_size][num_workers][ga]['cuda_calc_loss_time'].append(list(data['cuda_calc_loss_time'])[index] * scale)\n",
    "            results[model][mixed][batch_size][num_workers][ga]['cuda_backward_time'].append(list(data['cuda_backward_time'])[index] * scale)\n",
    "            results[model][mixed][batch_size][num_workers][ga]['cuda_update_time'].append(list(data['cuda_update_time'])[index] * scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[62.774052209854126]\n",
      "[57.311901927471155]\n",
      "[52.92064630317688]\n",
      "[50.224377614974976]\n",
      "\n",
      "\n",
      "[62.774052209854126]\n",
      "[57.311901927471155]\n",
      "[52.92064630317688]\n",
      "[50.224377614974976]\n",
      "\n",
      "[63.226546812057485]\n",
      "[57.34744355726242]\n",
      "[53.02533843421936]\n",
      "[50.24162372779846]\n",
      "\n",
      "[63.485773668766015]\n",
      "[57.44909517908097]\n",
      "[53.138583959579464]\n",
      "[50.29065523910523]\n",
      "\n",
      "[63.52852256917953]\n",
      "[57.55232306146622]\n",
      "[53.224043384552004]\n",
      "[50.29358042144776]\n",
      "\n",
      "120.4458889716193\n"
     ]
    }
   ],
   "source": [
    "model = 'resnet18'\n",
    "mixed = 'no'\n",
    "time = 'cuda_forward_time'\n",
    "# model | mixed | batch_size | num_workers | ga | time\n",
    "print(results[model][mixed]['32']['8']['1'][time])\n",
    "print(results[model][mixed]['64']['8']['1'][time])\n",
    "print(results[model][mixed]['128']['8']['1'][time])\n",
    "print(results[model][mixed]['256']['8']['1'][time])\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(results[model][mixed]['32']['8']['1'][time])\n",
    "print(results[model][mixed]['64']['8']['1'][time])\n",
    "print(results[model][mixed]['128']['8']['1'][time])\n",
    "print(results[model][mixed]['256']['8']['1'][time])\n",
    "print()\n",
    "\n",
    "print(results[model][mixed]['32']['8']['2'][time])\n",
    "print(results[model][mixed]['64']['8']['2'][time])\n",
    "print(results[model][mixed]['128']['8']['2'][time])\n",
    "print(results[model][mixed]['256']['8']['2'][time])\n",
    "print()\n",
    "\n",
    "print(results[model][mixed]['32']['8']['3'][time])\n",
    "print(results[model][mixed]['64']['8']['3'][time])\n",
    "print(results[model][mixed]['128']['8']['3'][time])\n",
    "print(results[model][mixed]['256']['8']['3'][time])\n",
    "print()\n",
    "\n",
    "print(results[model][mixed]['32']['8']['8'][time])\n",
    "print(results[model][mixed]['64']['8']['8'][time])\n",
    "print(results[model][mixed]['128']['8']['8'][time])\n",
    "print(results[model][mixed]['256']['8']['8'][time])\n",
    "print()\n",
    "\n",
    "r = results[model]['fp16']['256']['8']['1']\n",
    "\n",
    "print(r['cuda_forward_time'][0] + r['cuda_calc_loss_time'][0] + r['cuda_backward_time'][0] + r['cuda_update_time'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(496, 5) (496,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "batch = list()\n",
    "label = list()\n",
    "\n",
    "for model in list(results.keys()):\n",
    "    for mixed in list(results[model].keys()):\n",
    "        for batch_size in list(results[model][mixed].keys()):\n",
    "            for num_workers in list(results[model][mixed][batch_size].keys()):\n",
    "                for ga in list(results[model][mixed][batch_size][num_workers].keys()):\n",
    "                    cuda_forward_time = results[model][mixed][batch_size][num_workers][ga]['cuda_forward_time']\n",
    "                    cuda_calc_loss_time = results[model][mixed][batch_size][num_workers][ga]['cuda_calc_loss_time']\n",
    "                    cuda_backward_time = results[model][mixed][batch_size][num_workers][ga]['cuda_backward_time']\n",
    "                    cuda_update_time = results[model][mixed][batch_size][num_workers][ga]['cuda_update_time']\n",
    "                    \n",
    "                    total_time = cuda_forward_time[0] + cuda_calc_loss_time[0] + cuda_backward_time[0] + cuda_update_time[0]\n",
    "                    \n",
    "                    num_model = int(model.replace(\"resnet\", \"\"))\n",
    "                    if mixed == 'no':\n",
    "                        num_mixed = 32\n",
    "                    else:\n",
    "                        num_mixed = 16\n",
    "                    num_batch_size = int(batch_size)\n",
    "                    num_num_workers = int(num_workers)\n",
    "                    num_ga = int(ga)\n",
    "                    \n",
    "                    instance = [num_model, num_mixed, num_batch_size, num_num_workers, num_ga]\n",
    "                    batch.append(instance)\n",
    "                    label.append(total_time)\n",
    "\n",
    "np_batch = np.array(batch)\n",
    "np_label = np.array(label)\n",
    "print(np_batch.shape, np_label.shape)\n",
    "\n",
    "np.save('np_batch', np_batch)\n",
    "np.save('np_label', np_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
